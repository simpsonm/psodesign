\documentclass[12pt]{article}
\setlength{\oddsidemargin}{-0.125in}
\setlength{\topmargin}{-0.5in} \setlength{\textwidth}{6.5in}
\setlength{\textheight}{9in}

\setlength{\textheight}{9in} \setlength{\textwidth}{6.5in}
\setlength{\topmargin}{-40pt} \setlength{\oddsidemargin}{0pt}
\setlength{\evensidemargin}{0pt}

\setlength{\textheight}{8.5in} \setlength{\textwidth}{6.5in}
\setlength{\topmargin}{-36pt} \setlength{\oddsidemargin}{0pt}
\setlength{\evensidemargin}{0pt} \tolerance=500
\renewcommand{\baselinestretch}{1.5}

\usepackage{amssymb, amsmath, latexsym, array, morefloats, epsfig, rotating, graphicx}
\usepackage{subfigure, url, mathtools, enumerate, wasysym, threeparttable, lscape}
\usepackage{natbib,color}
\usepackage{bm, bbm,epstopdf}
\usepackage{xr, zref, hyperref}

\newenvironment{proof}[1][Proof]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}
\newenvironment{definition}[1][Definition]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}
\newenvironment{example}[1][Example]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}
\newenvironment{remark}[1][Remark]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}

\newcommand{\var}{\mathrm{var}}
\newcommand{\cov}{\mathrm{cov}}
\newcommand{\E}{\mathrm{E}}
\newcommand{\tr}{\mathrm{tr}}

\newcommand{\qed}{\nobreak \ifvmode \relax \else
      \ifdim\lastskip<1.5em \hskip-\lastskip
      \hskip1.5em plus0em minus0.5em \fi \nobreak
      \vrule height0.75em width0.5em depth0.25em\fi}

%- Makes the section title start with Appendix in the appendix environment
 \newcommand{\Appendix}
 {%\appendix
 \def\thesection{\Alph{section}}
 \def\thesubsection{\Alph{section}.\arabic{subsection}}
 \def\theequation{\Alph{section}.\arabic{equation}}
 \def\thealg{\Alph{section}.\arabic{alg}}
 %\def\thesubsection{A.\arabic{subsection}}
 }

\DeclareMathOperator{\vect}{vec}
\DeclareMathOperator{\vech}{vech}
\DeclareMathOperator{\diag}{diag}

\newtheorem{alg}{Algorithm}

% if variable blind is undefined, assume it is 0
\makeatletter
\@ifundefined{blind}{\def\blind{0}}{}
\makeatother

% if not blinded, reference unblinded appendix
\if0\blind
{
  \externaldocument{psokrigingapp}
}\fi

% if blinded, reference blinded appendix
\if1\blind
{
  \externaldocument{psokrigingappblind}
}\fi


\begin{document}
\thispagestyle{empty} \baselineskip=28pt

\begin{center}
{\LARGE{\bf Adaptively-Tuned Particle Swarm Optimization with Application to Spatial Design}}
\end{center}

\baselineskip=12pt
%%
\vskip 2mm
% if not blinded, give the authors
\if0\blind
{
  \begin{center}
    Matthew Simpson\footnote{(\baselineskip=10pt to whom correspondence should be addressed)
      Department of Statistics, University of Missouri,
      146 Middlebush Hall, Columbia, MO 65211-6100, themattsimpson@gmail.com}
    % Matthew Simpson,\footnote{(\baselineskip=10pt to whom correspondence should be addressed)
    % Department of Statistics, University of Missouri,
    % 146 Middlebush Hall, Columbia, MO 65211-6100, themattsimpson@gmail.com}
    % Christopher K. Wikle,\footnote{\label{note:aff}\baselineskip=10pt
    % Department of Statistics, University of Missouri,
    % 146 Middlebush Hall, Columbia, MO 65211-6100}
    % and Scott H. Holan\textsuperscript{\ref{note:aff}}
  \end{center}
} \fi

\vskip 2mm
\begin{center}
{\large{\bf Abstract}}
\end{center}
\baselineskip=12pt 

\baselineskip=12pt
\par\vfill\noindent
{\bf KEY WORDS:} 

\par\medskip\noindent


\clearpage\pagebreak\newpage \pagenumbering{arabic}
\baselineskip=24pt

\section{Introduction}
Particle swarm optimization (PSO) refers to a large class of heuristic optimization algorithms that use an analogy with animal flocking behavior in order to construct more robust optimization algorithms than many alternatives \citep{clerc2002particle,blum2008swarm,clerc2010particle}. This robustness makes them attractive for more difficult optimization problems, especially when near optimal solutions are tolerable. We introduce a new class of PSO algorithms, called adaptively tuned PSO (AT-PSO), which exploit an analogy with a class of adaptive Markov chain Monte Carlo algorithms in order to tune a crucial parameter of the PSO algorithm adaptively based on the state of th particle swarm. We show that the resulting algorithms tend to be superior to many PSO alternatives. Additionally, we several PSO algorithms by applying them to choosing a set of new monitoring locations for ozone in Harris County, Texas, where Houston is located. Section \ref{sec:pso} introduces various PSO and AT-PSO algorithms, and briefly discusses the results of an extended simulation study comparing them. Section \ref{sec:spatialdesign} introduces the generic spatial design problem and the Houson area ozone problem as an instance of that problem, and compares several PSO algorithms and some alternatives to solving the problem. Finally, Section \ref{sec:discuss} discusses our results and concludes.

\section{Particle swarm optimization}\label{sec:pso}
We briefly describe PSO here; refer to \citet{blum2008swarm} for an excellent introduction and \citet{clerc2010particle} for details. Suppose that we wish to maximize some objective function $Q(\bm{\theta}):\Re^D\to\Re$. Let $i=1,2,\dots,n$ index a set of particles over time, $t=1,2,\dots,T$, where in every period each particle consists of a location $\bm{\theta}_i(t)\in \Re^D$, a velocity $\bm{v}_i(t) \in \Re^D$, a personal best location $\bm{p}_i(t)\in\Re^D$, and a group best location $\bm{g}_i(t)\in\Re^D$. Here we mean ``best'' in the sense of maximizing $Q$, so $Q(\bm{p}_i(t)) \geq Q(\bm{\theta}_i(s))$ for any $s\leq t$. The group best location is defined with respect to some neighborhood $\mathcal{N}_i$ of particle $i$; that is, $\bm{g}_i(t) = \arg\max_{\{\bm{p}_j(t)|j\in\mathcal{N}_i\}}Q(\bm{p}_j(t))$. In the simplest case where the entire swarm is the neighborhood of each particle, $\bm{g}_i(t)\equiv \bm{g}(t) = \arg\max_{\{\bm{p}_j(t)|j\in 1:n\}}Q(\bm{p}_j(t))$. The generic PSO algorithm updates as follows for each particle $i$:
\begin{align}\label{eq:pso}
\bm{v}_i(t+1) &= \omega \bm{v}_i(t) + \phi_1 \bm{r}_{1i}(t)\circ\{\bm{p}_i(t) - \bm{\theta}_i(t)\} + \phi_2 \bm{r}_{2i}(t)\circ\{\bm{g}_i(t) - \bm{\theta}_i(t)\},\nonumber\\
\bm{\theta}_i(t+1) &= \bm{\theta}_i(t) + \bm{v}_i(t+1),\nonumber\\
\bm{p}_i(t+1) &= \begin{cases} \bm{p}_i(t)   & \mbox{if }\  Q(\bm{p}_i(t)) \ge Q(\bm{\theta}_i(t + 1))\\
                               \bm{\theta}_i(t+1) & \mbox{otherwise},
\end{cases}\nonumber\\
\bm{g}_i(t+1) &= \arg\max_{\{\bm{p}_j(t+1)|j\in\mathcal{N}_i\}}Q(\bm{p}_j(t+1)),
\end{align}
where $\circ$ denotes the Hadamard product (element-wise product), $\bm{r}_{1i}(t)$ and $\bm{r}_{2i}(t)$ are each vectors of $D$ random variates independently generated from the $U(0,1)$ distribution, and $\omega>0$, $\phi_1>0$, and $\phi_2>0$ are user-defined parameters. The term $\omega \bm{v}_i(t)$ controls the particle's tendency to keep moving in the direction it is already going, so $\omega$ is called the inertia parameter. For $\omega<1$ velocities tend to decrease over time, while for $\omega>1$ they tend to increase over time. Similarly $\phi_1 \bm{r}_{1i}(t)\circ\{\bm{p}_i(t) - \bm{\theta}_i(t)\}$ controls the particle's tendency to move towards its personal best location while $\phi_2 \bm{r}_{2i}(t)\circ\{\bm{g}_i(t) - \bm{\theta}_i(t)\}$ controls its tendency to move toward its group best location, so $\phi_1$ and $\phi_2$ are called the cognitive correction factor and social correction factor, respectively \citep{blum2008swarm}. This version of PSO is equivalent to \citet{clerc2002particle}'s constriction type I particle swarm, though there are many other variants. A default version choice sets $\omega = 0.7298$ and $\phi_1 = \phi_2 = 1.496$; see \citet{clerc2002particle} for justification. Even when $\omega<1$, if $\phi_1$ and $\phi_2$ are set high enough the velocities of the particles can continually increase and cause the swarm to make jumps that are much too large. A heavy handed way to solve this problem is by setting an upper bound on the velocity of any particle in any given direction, called velocity clamping. However, the default parameter values suggested by \citet{clerc2002particle} are also designed to prevent velocity explosion.

Any PSO variant can also be combined with various neighborhood topologies that control how the particles communicate to each other. The default global topology allows each particle to see each other particle's previous best location for the social components of their respective velocity updates, but this can cause inadequate exploration and premature convergence. Alternative neighborhood topologies limit how many other particles each particle can communicate with. The ring-$k$ topologies do this by only allowing each particle to see the $k$ particles to its left and the $k$ particles to its right when the particles are arranged in a ring. For example, particle 1 may only look at itself and particles 2, 3, $n$, and $n-1$ when determining its group best location. This slows down the transfer of information across the swarm so that each particle spends more time exploring. Several other neighborhood topolgies can be used, see [CITATIONS]

Bare bones PSO (BBPSO) is a variant of PSO introduced by \citet{kennedy2003bare} that strips away the velocity term. Let $\theta_{ij}(t)$ denote the $j$th coordinate of the position for the $i$th particle in period $t$, and similarly for $p_{ij}(t)$ and $g_{ij}(t)$. Then the BBPSO algorithm obtains a new position coordinate $\theta_{ij}$ via
\begin{align}\label{eq:bbpso}
\theta_{ij}(t+1) \sim N\left(\frac{p_{ij}(t) + g_{ij}(t)}{2}, |p_{ij}(t) - g_{ij}(t)|^2\right).
\end{align}
The updates of $\bm{p}_i(t)$ and $\bm{g}_i(t)$ are the same as in \eqref{eq:pso}. There are several variants of this algorithm, for example \citet{krohling2009bare}, \citet{hsieh2010modified}, \citet{richer2006levy}, and \citet{campos2014bare}. Appendix \ref{subapp:bbpso} contains more detail on some of these BBPSO variants.

\subsection{Adaptively tuned BBPSO}\label{subsec:ATBBPSO}
BBPSO adapts the size effective search space of the swarm over time through the variance term, $|p_{ij}(t) - g_{ij}(t)|^2$. As the personal best locations of the swarm move closer together, these variances decrease and the swarm explores locations which are closer to known high value areas in the space. This behavior is desirable, but the adaptation is forced to occur only through personal and group best locations. In order to allow it to adapt in a more flexible manner, we modify the BBPSO variance to $\sigma^2(t)|p_{ij}(t) - g_{ij}(t)|^2$ and tune $\sigma^2(t)$ in a manner similar to adaptive random walk Metropolis MCMC algorithms \citep{andrieu2008tutorial}. Define the improvement rate of the swarm in period $t$ as $R(t) = \#\{i:Q(\bm{p}_i(t))> Q(\bm{p}_i(t-1))\}/n$ where $\#A$ is the number of members of the set $A$, and let $R^*$ denote the target improvement rate. Then adaptively tuned BBPSO (AT-BBPSO) updates the swarm's personal best and group best locations as in \eqref{eq:pso}, then updates particle locations as follows:
\begin{align}\label{eq:at-bbpso}
\theta_{ij}(t+1) &\sim t_{df}\left(\frac{p_{ij}(t) + g_{ij}(t)}{2}, \sigma^2(t)|p_{ij}(t) - g_{ij}(t)|^2\right),\nonumber\\
\log \sigma^2(t+1) &= \log\sigma^2(t) + c\times\{R(t+1) - R^*\},
\end{align}
where $df$ is a user chosen degrees of freedom parameter and $c$ is another user chosen parameter that controls the speed of adaptation. We use a $t$ kernel instead of a Gaussian in order to allow for more flexibility, and we find $df=1$ appears to combine well with adaptively tuning $\sigma^2(t)$. Setting the target rate from $R^*=0.3$ to $R^*=0.5$ tends to yield good AT-BBPSO algorithms, which is unsurprising given the connection to adaptive random walk Metropolis \citep{gelman1996efficient}. The parameter $c$ controls the speed of adaptation so that larger values of $c$ mean the algorithm adapts $\sigma^2(t)$ faster. We find that $c=0.1$ to be a good value, though anything within an order of maginitude yields similar results. We use $\sigma^2(0)=1$ to initialize the algorithm at the standard BBPSO algorithm.

Both using a $t$ kernel and adding a fixed scale parameter have been discussed in the BBPSO literature, but as \citet{kennedy2003bare} notes, something about setting $\sigma=1$ is special that causes the algorithm to work well. Another similar BBPSO algorithm in the literature comes from \citet{hsieh2010modified}. They propose a modified version of BBPSO with 
\begin{align*}
\theta_{ij}(t+1) \sim N\left(\omega\frac{p_{ij}(t) + g_{ij}(t)}{2}, \sigma^2|p_{ij}(t) - g_{ij}(t)|^2\right),
\end{align*}
where $\omega\leq 1$ and $\sigma^2\leq 1$ are constriction parameters that are eventually both set to one after enough iterations of the algorithm. The authors suggest dynamically adjusting the constriction parameters in the early stage of the algorithm before they are set to one, but give no suggesption for how to do this. AT-BBPSO algorithm is able to adapt its value on the fly based on local knowledge about the objective function. If too much of the swarm is failing to find new personal best locations, AT-BBPSO proposes new locations closer to known high value areas. If too much of the swarm is improving, AT-BBPSO proposes bolder locations in an effort to make larger improvements. This ability to adapt to local information about the objective function allows AT-BBPSO to more quickly traverse the search space towards the global optimum, though by using local information AT-BBPSO does risk premature convergence to a local optimum. The adaptively tuned component of AT-BBPSO can also be combined with most BBPSO variants, some of which are outlined in Appendix \ref{subapp:bbpso}. In Appendix \ref{app:psocompare} we conduct a simulation study on several test functions that compares AT-BBPSO variants to other PSO and BBPSO variants in order to justify the parameter settings discussed above and demonstrate AT-BBPSO variants are attractive PSO algorithms.

\subsection{Adaptively tuned PSO}\label{sec:AT-PSO}
In AT-BBPSO variants, the parameter $\sigma(t)$ partially controls the effective size of the swarm's search area, and we increase or decrease $\sigma(t)$ and consequently the search area depending on how much of the swarm is finding new personal best locations. In standard PSO the inertia parameter, denoted by $\omega$ in \eqref{eq:pso}, is roughly analogous to $\sigma^2$ in BBPSO. It controls the effective size of the swarm's search area by controlling how the magnitude of the velocities evolve over time. In AT-BBPSO we use an analogy with tuning a random walk Metropolis-Hastings MCMC algorithm in order to build intuition about how to tune $\sigma(t)$. The analogy is much weaker in this case; nonetheless, the same mechanism works well to tune $\omega(t)$.

The idea of time-varying $\omega(t)$ has been in the PSO literature for some time. An early suggestion was to set $\omega(0)=0.9$ and deterministically decrease it until it reaches $\omega(T)=0.4$ after the maximum number of iterations allowed \citep{eberhart2000comparing}. In particular, \citet{tuppadung2011comparing} suggest defining $\omega(t)$ via the parameterized inertia weight function
\begin{align}\label{eq:inertiafun}
\omega(t) = \frac{1}{1 + \left(\frac{t}{\alpha}\right)^{\beta}}
\end{align}
where $\alpha$ and $\beta$ are user-defined parameters. Roughly, $\alpha$ controls how low $\omega(t)$ can go and $\beta$ controls how fast it gets there, so $\alpha$ and $\beta$ can be thought of as intercept and slope parameters respectively. The suggestion in \citet{tuppadung2011comparing} is to set $\alpha$ to a small fraction of the total amount of iterations in which the algorithm is allowed to run (e.g., 10\% or 20\%), and set $\beta$ between one and four. We call this type of PSO algorithm deterministic inertia PSO (DI-PSO).

DI-PSO tends to improve on standard PSO if $\omega(t)$'s progression is set appropriately, but it invariably makes using PSO more difficult for the average user. Additionally, depending on the problem, it may be more useful to let the swarm explore the space for more or less iterations, necessitating different progressions of $\omega(t)$. A priori it may not be clear exactly which approach is best for any given problem, so an automatic method is desirable. Adaptively tuned PSO (AT-PSO) is just that --- it provides an automatic method to adjust the value of $\omega(t)$ depending on local information obtained by the particle swarm. Formally, AT-PSO updates personal and group best locations as in \eqref{eq:pso} and updates $\omega(t)$ and particle locations as follows:
\begin{align}\label{eq:atpso}
\bm{v}_i(t+1) &= \omega(t+1) \bm{v}_i(t) + \phi_1 \bm{r}_{1i}(t)\circ\{\bm{p}_i(t) - \bm{\theta}_i(t)\} + \phi_2 \bm{r}_{2i}(t)\circ\{\bm{g}_i(t) - \bm{\theta}_i(t)\},\nonumber\\
\bm{\theta}_i(t+1) &= \bm{\theta}_i(t) + \bm{v}_i(t+1),\nonumber\\
\log\omega(t+1)& = \log\omega(t) + c\times\{R(t+1) - R^*\},
\end{align}
where $R(t)$ is the improvement rate of the swarm in iteration $t$, $R^*$ is the target improvement rate, and $c$ controls how much $R(t)$ changes on a per iteration basis. Again, we find that target rates from $R^*=0.3$ to $0.5$ work well for AT-PSO. The value of $c$ controls the speed of adaptation, and in particular if $c$ is small and $\omega(0)$ is large, AT-PSO can mimic DI-PSO to some extent. This turns out to produce poor AT-PSO algorithms, however. We use $c=0.1$ as a default value and in simulations not reported here, we find that the gains from optimizing $c$ appear to be small. However, very small values like those suggested by an attempt to mimic DI-PSO turn out to cause the algorithm to perform very poorly. 

A major strength of AT-PSO relative to DI-PSO and standard PSO is that AT-PSO can increase $\omega(t)$ when information from the swarm suggests there is an unexplored high value region of the space. Just like in AT-BBPSO, this mechanism provides a way for the swarm to adapt its behavior on the fly based on local conditions and speed up convergence by allowing the particles that do improve to make larger improvements, but it can also cause premature convergence to a local optimum. While DI-PSO monotonically decreases $\omega(t)$ toward some minimum value, AT-PSO typically oscillates $\omega(t)$ so that the algorithm alternates between exploring and exploiting more, relative to standard PSO. Appendix \ref{app:psocompare} contains an extended simulation study comparing a variety of these PSO and BBPSO algorithms on a suite of test functions that demonstrates some of the behavior detailed above and shows that AT-PSO is an attractive PSO algorithm. 

\section{The Spatial Design Problem}\label{sec:spatialdesign}
Suppose we are interested predicting some spatially indexed response variable $Y(\bm{u})$, $\bm{u}\in \mathcal{D}\subseteq \Re^2$ at a set of target locations $\bm{t}_1, \bm{t}_2, \dots, \bm{t}_{N_t}\in\mathcal{D}$. Let $\bm{s}_1, \bm{s}_2, \dots, \bm{s}_{N_s}\in\mathcal{D}$ denote a set of $N_s$ fixed sampling locations within the spatial domain. The design problem is to add $N_d$ new sampling locations in order to optimize the amount we learn about $Y(\bm{u})$ at the target locations. Let $\bm{d}_1, \bm{d}_2, \dots, \bm{d}_{N_d}\in\mathcal{D}$ denote a set of candidate design points and suppose that $Y(\bm{u})$ is a geostatistical process with mean function $\mu(\bm{u})=\bm{x}(\bm{u})'\bm{\beta}$ for some covariate $\bm{x}(\bm{u})$ known at every point in $\mathcal{D}$ and some covariance function $C(\bm{u}, \bm{v})$ for $\bm{u},\bm{v}\in\mathcal{D}$. Not all covariates can be known a priori at every point in the spatial domain, but e.g. covariates that are known functions of the location satisfy this constraint. Once the design points are selected, we observe $Z(\bm{d}_i)$ for $i=1,2,\dots,N_d$ and $Z(\bm{s}_i)$ for $i=1,2,\dots,N_s$ where $Z(\bm{u}) = Y(\bm{u}) + \varepsilon(\bm{u})$ and $\varepsilon(\bm{u})$ is mean zero white noise with variance $\tau^2$, representing measurement error. Typically $\bm{\beta}$, $\tau^2$, and $C(.,.)$ are unknown and must be estimated, though for now we will treat them as known.

To completely specify the problem we need to define an informative design criterion. Intuitively, the larger the mean square prediction error (MSPE), i.e. the kriging variance, is at each of the target locations, the less information we have about $Y(\bm{u})$ at those locations. A common design criterion is to optimize function of these variances, e.g. to minimize the mean kriging variance or the maximum kriging variance over all target locations. These criteria are somewhat naive since they they ignore parameter uncertainty, and taking that into account will often change the optimal design \citep{zimmerman2006optimal}. In the Bayesian context, the standard design criterion is the expected entropy gain from observing the data \citep{ebrahimi2010information}, e.g. in \cite{fuentes2007bayesian}, and it can be adapted to both the case of known and unknown parameters. Though PSO can be applied to design problems with any combination of known and unknown parameters, for simplicity we consider minimizing both mean and maximum kriging variance under universal kriging where only $\bm{\beta}$ and $\{Y(\bm{u}):\bm{u}\in\mathcal{D}\}$ are treated as unknown.

\subsection{Universal Kriging}
In universal kriging, $C(.,.)$ and $\tau^2$ are treated as known while $\bm{\beta}$ is treated as a parameter that neeeds to be estimated. Let $\bm{Z}$ the vector of $Z(\bm{s}_i)$s and $Z(\bm{d}_i)$s, $\bm{X}$ denote the corresponding stacked $\bm{x}(\bm{s}_i)'$s and $\bm{x}(\bm{d}_i)'$s, $\bm{C}_Z = \cov(\bm{Z})$ where $\cov[Z(\bm{u}), Z(\bm{v})] = C(\bm{u},\bm{v}) + \sigma^2_\varepsilon 1(\bm{u} = \bm{v})$, and $\bm{c}_Y(\bm{t}_i) = \cov[Y(\bm{t}_i), \bm{Z}]$ where $\cov[Y(\bm{t}_i), Z(\bm{u})] = C(\bm{t}_i, \bm{u})$. The universal kriging predictor of $Y(\bm{t}_i)$ is \citep[Section~4.1.2]{cressie2015statistics}
\begin{align*}
\widehat{Y}_{uk}(\bm{t}_i;\bm{d}) &= \bm{x}(\bm{t}_i)'\widehat{\bm{\beta}}_{gls} + \bm{c}_Y(\bm{t}_i)'\bm{C}_Z^{-1}(\bm{Z} - \bm{X}\widehat{\bm{\beta}}_{gls})\\
\intertext{where $\widehat{\bm{\beta}}_{gls} = [\bm{X}'\bm{C}_Z^{-1}\bm{X}]^{-1}\bm{X}'\bm{C}_Z^{-1}\bm{Z}$ is the generalized least squares estimate of $\bm{\beta}$, and the MSPE of $\widehat{Y}_{uk}(\bm{t}_i)$ is}
\sigma_{uk}^2(\bm{t}_i;\bm{d}) &= C(\bm{t}_i, \bm{t}_i) - \bm{c}_Y(\bm{t}_i)'\bm{C}_Z^{-1}\bm{c}_Y(\bm{t}_i)  \\
& + [\bm{x}(\bm{t}_i)  - \bm{X}'\bm{C}_Z^{-1}\bm{c}_Y(\bm{t}_i)]'[\bm{X}'\bm{C}_Z^{-1}\bm{X}]^{-1}[\bm{x}(\bm{t}_i)  - \bm{X}'\bm{C}_Z^{-1}\bm{c}_Y(\bm{t}_i)].
\end{align*}
To avoid clutter we drop the explicit dependence on $\bm{d}$ in these equations, but $\bm{c}_Y(\bm{t}_i)$, $\bm{C}_Z$, $\bm{Z}$, $\bm{X}$, and $\widehat{\bm{\beta}}_{gls}$ all depend on $\bm{d}$. The mean universal kriging variance is given by
\begin{align*}
\overline{Q}_{uk}(\bm{d}) &= \frac{1}{N_t}\sum_{i}^{N_t}\sigma^2_{uk}(\bm{t}_i;\bm{d})\\
\intertext{while the maximum universal kriging variance is given by}
Q_{uk}^*(\bm{d}) &= \max_{i=1,2\dots,N_t}\sigma^2_{uk}(\bm{t}_i;\bm{d}).
\end{align*}
In this context, \cite{zimmerman2006optimal} finds that the optimal design under both criteria is highly dependent on the class of mean function of the geostatistical process. In practice we are often interested in predicting at the entire spatial domain rather than a finite set of target locations. This changes the mean and maximum kriging variances to
\begin{align*}
\overline{Q}_{uk}(\bm{d}) &= \frac{1}{|\mathcal{D}|}\int_{\mathcal{D}}\sigma^2_{uk}(\bm{u};\bm{d})d\bm{u}\\
\intertext{and}
Q_{uk}^*(\bm{d}) &= \max_{\bm{u}\in\mathcal{D}}\sigma^2_{uk}(\bm{u};\bm{d}).
\end{align*}
respectively. We can approximate both of these with a large but finite sample of target locations from $\mathcal{D}$, though if the sample is too small some design critera may favor points directly on top of the sampled locations. 

\subsection{Accounting for Parameter Uncertainty}
[THIS NEEDS TO BE MERGED WITH THE REST OF THE DOCUMENT, BUT FOR NOW IT'S HERE]

Assuming that all covariance function parameters are known, the MSPE from kriging at an arbitrary location $\bm{u}$ is $\sigma_{uk}^2(\bm{u})$. This underestimates the MSPE when those parameters must be estimated. An approximation of this MSPE is given by \citep{zimmerman1992mean,abt1999estimating}
\begin{align*}
\E[Y(\bm{u}) - \widehat{Y}_{uk}(\bm{u})]^2 \approx \sigma^2_{fuk}(\bm{u};\bm{d},\bm{\theta}) = \sigma^2_{uk}(\bm{u};\bm{d},\bm{\theta}) + \tr[\bm{A}(\bm{u};\bm{d},\bm{\theta})\bm{I}^{-1}(\bm{d},\bm{\theta})]
\end{align*}
where $\bm{I}^{-1}$ is the inverse Fisher information (FI) matrix and $\bm{A} = \var[\partial \widehat{Y}_{uk} /\partial \bm{\theta}]$. The $ij$th element of the FI matrix can be derived as
\begin{align*}
\tr\left(\bm{C}_Z^{-1}\frac{\partial\bm{C}_Z}{\partial\theta_i}\bm{C}_Z^{-1}\frac{\partial\bm{C}_Z}{\partial\theta_j}\right).
\end{align*}
To derive $\bm{A}$ note that $\widehat{Y}_{uk}$ can be rewritten as
\begin{align*}
\widehat{Y}_{uk}(\bm{u}) = \bm{x}(\bm{u})'\bm{U}'\bm{Z} + \bm{c}_Y(\bm{u})'\bm{V}'\bm{Z}
\end{align*}
where $\bm{U} = \bm{C}_Z^{-1}\bm{X}(\bm{X}'\bm{C}_Z^{-1}\bm{X})^{-1}$ and $\bm{V} = \bm{C}_Z^{-1} - \bm{U}\bm{X}'\bm{C}_Z^{-1}$. Then elementary matrix calculus yields
\begin{align*}
\frac{\partial \widehat{Y}_{uk}(\bm{u})}{\partial \theta_i} &= \bm{x}(\bm{u})'\frac{\partial \bm{U}}{\partial \theta_i}'\bm{Z} + \frac{\partial \bm{c}_Y(\bm{u})}{\partial \theta_i}'\bm{V}'\bm{Z} + \bm{c}_Y(\bm{u})'\frac{\partial \bm{V}}{\partial \theta_i}'\bm{Z}\\
&= \left[-\bm{V}\frac{\partial \bm{C}_Z}{\partial \theta_i}\bm{U}\bm{x}(\bm{u}) - \bm{V}\frac{\partial \bm{C}_Z}{\partial \theta_i}\bm{V}\bm{c}_Y(\bm{u}) + \bm{V}\frac{\partial \bm{c}_Y(\bm{u})}{\partial \theta_i}\right]'\bm{Z}\\
&\equiv\bm{\delta}_i'\bm{Z}.
\end{align*}
Then 
\begin{align*}
\bm{A} = \var\left[\frac{\partial \widehat{Y}_{uk}(\bm{u})}{\partial \bm{\theta}}\right] = \var[\bm{\Delta}'\bm{Z}] = \bm{\Delta}'\bm{C}_Z^{-1}\bm{\Delta}
\end{align*}
where $\bm{\Delta} = (\bm{\delta}_1, \bm{\delta}_2, \dots, \bm{\delta}_p)$.
\subsection{Houston Ozone Monitoring}\label{sec:houston}
The Texas Commission on Environmental Quality (TCEQ) publishes a variety of environmental data for Texas, including many environmental indicators that directly relate to public health. We focus on ozone in the Houston-Galveston-Brazoria area. The TCEQ measures ozone at a variety of monitoring locations in this area and publishes daily maximum eight-hour ozone concentrations (DM8s) in parts per billion (ppb) for each monitoring location. DM8s are computed as follows. First, the TCEQ creates publishes an hourly average (in ppb) for each monitoring location. Then an eight hour average is constructed at that location for each contiguous eight-hour period where all eight measurements were present for a given day. The maximum of these eight-hour averages for a given day is the published DM8. Days with less than 18 valid eight-hour averages have no published DM8.

In August 2016 there were 44 active monitoring locations in the Houston-Galveston-Brazoria area. For each location $\bm{u}$ we compute the monthly average DM8, which we denote by $Z(\bm{u})$. At one location, MRM-3 Haden Road, there are two DM8 observations of 0 ppb in the month of August. We assume that these were data errors and throw them out for the purposes of computing $Z(\bm{u})$ at that location. Of the 44 locations, one has 15 valid DM8 measurements of 31 possible valid measurements, another has 24 valid measurements, and the rest of the locations have at least 27 valid measurements. 

The hypothetical design problem we consider is the addition of five new ozone monitoring locations to the Houston-Galveston-Brazoria monitoring network in Harris County, where Houston is located, with the goal of predicting ozone concentrations within Harris County. Of the 44 existing locations, 33 are already in Harris County, though the locations outside of the county are still useful for spatial prediction within Harris County. 

Let $Z(\bm{u})$ denote the measured average DM8 as location $\bm{u}$ and let $Y(\bm{u})$ denote the true DM8. We assume that $Z(\bm{u})$ is a noisy Gaussian measurement of $Y(\bm{u})$, i.e. the data model is $Z(\bm{u}) \sim N[Y(\bm{u}), s_Z^2(\bm{u}) + \tau^2]$. The measurement error is broken into two pieces which we assume are independent: pure measurement error with variance $\tau^2$, and sampling error with variance $s_Z^2(\bm{u})$. Sampling error occurs from measuring DM8 on less than the full 31 days in August. We assume that the measured days are randomly sampled from the 31 possible days so that the sampling error for $Z(\bm{u})$ is $s_Z^2(\bm{u}) = s^2_{DM8}(\bm{u})[31 - n(\bm{u})]/[31n(\bm{u})]$ where $s^2_{DM8}(\bm{u})$ is the sample variance of the DM8 measurements at location $\bm{u}$ and $n(\bm{u})$ is the number of measurements at that location. Note that if $n(\bm{u})=31$, the maximum number of possible DM8 measurements, then $s^2_Z(\bm{u}) = 0$. This sampling model is almost certainly incorrect since missing DM8 measurements at a given location tend to be contiguous in time, but it is a useful approximation as long as the probability of a given day being measured is largely unrelated to the true DM8 at that location.

At the process level, we assume that $Y(\bm{u})$ is a geostatistical process with mean function $\mu(\bm{u}) = \bm{x}(\bm{u})'\bm{\beta}$ and exponential covariance function $C(\bm{u},\bm{v}) = \sigma^2\exp(-||\bm{u} - \bm{v}||/\phi)$. We assume that any fine scale variability is measurement error and captured by the data model variance $s_Z^2(\bm{u}) + \tau^2$. We considered several possible mean functions: constant in $\bm{u}$, linear in $\bm{u}$, and quadratic in $\bm{u}$. We fit each model using maximum likelihood and found that quadratic terms were unnecessary, but linear terms did significantly help explain variation in $Y(\bm{u})$. Further, both AIC and BIC were essentially indifferent between the linear and constant mean models, so we use the linear model. Note that this model is a slight departure from the class considered in Section \ref{sec:spatialdesign}. We use the same notation in that section as in this section so that, e.g., $\bm{u}$ is a generic location inside $\mathcal{D}$, which can be considered to be the entire Houston-Galveston-Brazoria area, $\bm{s}_i$ is an existing monitoring location, $\bm{t}_i$ is a target location, and $\bm{d}_i$ is a proposed location for a new monitoring station. The only difference is that in Section \ref{sec:spatialdesign} $\bm{C}_Z = \tau^2\bm{I} + \bm{C}_Y$, whereas in this section $\bm{C}_Z = \bm{S}_Z^2 + \tau^2\bm{I} + \bm{C}_Y$ where $\bm{S}_Z^2$ is a diagonal matrix with $[s_Z^2(\bm{s}_1), s_Z^2(\bm{s}_2), \dots, s_Z^2(\bm{s}_{N_s}), 0, \dots, 0]$ along the diagonal. This assumes that $s_Z^2(\bm{d}_i)=0$ for $i=1,2,\dots,N_d$, in other words that each new monitoring station will record a valid DM8 for every day of a given month so that there is no sampling error. [NOTE: WE SHOULD OBVIOUSLY FIT THE MODEL USING THE $s_Z^2(\bm{s}_{i})$s, BUT FOR KRIGING SHOULD WE ASSUME $s_Z^2(\bm{s}_{i})=0$? OR MAYBE SOME OTHER VALUE? BASICALLY, SHOULD WE EXPECT SAMPLING ERROR AND TO WHAT DEGREE?]

We use two design criteria in order to choose the five new locations in Harris County: $\overline{Q}_{uk}(\bm{d})$ and $Q^*_{uk}(\bm{d})$, both defined in Section \ref{sec:spatialdesign}. For both criteria we plug in the MLEs for $\tau^2$, $\sigma^2$, and $\phi$. We assume that the goal is the predict average DM8 in all of Harris County, so we approximate the continuous versions of $\overline{Q}_{ik}(\bm{d})$ and $Q^*_{uk}(\bm{d})$ with the finite sample versions using a sample of 1,000 locations drawn uniformly from Harris County. We try a variety of PSO algorithms in order to select the new locations. Since the design space only allows new monitoring locations within Harris County, we define $\overline{Q}_{uk}(\bm{d})=Q^*_{uk}(\bm{d})=\infty$ when any of the proposed locations are outside of Harris County.

[INSERT PSO RESULTS HERE... CURRENTLY RUNNING/PENDING TO BE RUN ON THE SERVER, THOUGH WE MAY WANT TO TWEAK IT - TAKES 2-3 DAYS TO RUN]

\section{Discussion}\label{sec:discuss}
[TO BE WRITTEN]

\clearpage\pagebreak\newpage\thispagestyle{empty}
\bibliographystyle{../jasa}
\bibliography{../pso}
\end{document}
